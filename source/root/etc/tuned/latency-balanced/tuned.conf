#
# tuned configuration
#

[main]
summary=Less power-hungry version of latency-performance profile
include=latency-performance

[bootloader]
cmdline=clocksource=hpet

[cpu]
governor=schedutil

[vm]
transparent_hugepages=madvise

[sysfs]
# force full speed at the first core of the first CPU so
# non-demanding realtime programs, such as JACK, may be forced on it
#/sys/devices/system/cpu/cpu0/cpufreq/scaling_governor=performance

[sysctl]
# better clock:
# http://wiki.linuxaudio.org/wiki/system_configuration
dev.hpet.max-user-freq=4096

# https://wiki.gentoo.org/wiki/Traffic_shaping#Theory
net.core.default_qdisc=fq_codel

# it may actually hurt load balancing:
# https://unix.stackexchange.com/questions/277505/why-is-nice-level-ignored-between-different-login-sessions-honoured-if-star
#kernel.sched_autogroup_enabled=0

# Minimal preemption granularity for CPU-bound tasks:
# (default: 1 msec#  (1 + ilog(ncpus)), units: nanoseconds)
kernel.sched_min_granularity_ns=100000

# The total time the scheduler will consider a migrated process
# "cache hot" and thus less likely to be re-migrated
# (system default is 500000, i.e. 0.5 ms)
kernel.sched_migration_cost_ns=10000000

# inspired by https://forums.gentoo.org/viewtopic-p-8001720.html
kernel.sched_latency_ns=1000000
kernel.sched_wakeup_granularity_ns=1000
# aggressiveness of task migration between CPUs
kernel.sched_nr_migrate=4
kernel.sched_cfs_bandwidth_slice_us=1000

# for JACK and better realtime
kernel.sched_rt_period_us=1000000
# this doesn't work with CONFIG_RT_GROUP_SCHED and must be -1 (unlimited) which is dangerous due to system lock-ups
kernel.sched_rt_runtime_us=900000
# granularity of RT. 25 is recommended, 100 is default
kernel.sched_rr_timeslice_ms=50

# If a workload mostly uses anonymous memory and it hits this limit, the entire
# working set is buffered for I/O, and any more write buffering would require
# swapping, so it's time to throttle writes until I/O can catch up.  Workloads
# that mostly use file mappings may be able to use even higher values.
#
# The generator of dirty data starts writeback at this percentage (system default
# is 20%)
vm.dirty_ratio=50

# Start background writeback (via writeback threads) at this percentage (system
# default is 10%)
vm.dirty_background_ratio=5

# The swappiness parameter controls the tendency of the kernel to move
# processes out of physical memory and onto the swap disk.
# 0 tells the kernel to avoid swapping processes out of physical memory
# for as long as possible
# 100 tells the kernel to aggressively swap processes out of physical memory
# and move them to swap cache
#vm.swappiness=1
